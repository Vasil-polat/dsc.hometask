{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e75d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9cd249c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU доступний: True\n",
      "Назва GPU: Quadro P2000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"GPU доступний:\", torch.cuda.is_available())\n",
    "print(\"Назва GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b26e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be49510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_examples = list(open(\"data/rt-polarity.pos\", \"r\").readlines())\n",
    "positive_examples = [s.strip() for s in positive_examples]\n",
    "negative_examples = list(open(\"data/rt-polarity.neg\", \"r\").readlines())\n",
    "negative_examples = [s.strip() for s in negative_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6591d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text': negative_examples + positive_examples,\n",
    "              'lable': [0]*len(negative_examples) + [1]*len(positive_examples)})\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72e41c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['lable'], stratify=df['lable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e98c72",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "# **FAISS**\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3893ace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7244929f82ea46819e56e3e94ddcf517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\faiss_gpu_env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:408: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819d0da324b44a96b0b58e40763c8a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n",
    "\n",
    "\n",
    "train_embeddings = model.encode(X_train.tolist(), normalize_embeddings=True, show_progress_bar=True)\n",
    "test_embeddings = model.encode(X_test.tolist(), normalize_embeddings=True, show_progress_bar=True)\n",
    "faiss.normalize_L2(train_embeddings)\n",
    "faiss.normalize_L2(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d7287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7996 7996\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(train_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc5d7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the index: 7996\n"
     ]
    }
   ],
   "source": [
    "d = train_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(np.array(train_embeddings).astype('float32'))\n",
    "print(f\"Number of vectors in the index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "647ea2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "distances, indices = index.search(np.array(test_embeddings).astype('float32'), k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64715935",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for neighbor_idxs in indices:\n",
    "    neighbor_labels = [y_train.tolist()[i] for i in neighbor_idxs]\n",
    "    pred = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predictions.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d39580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['Method', 'Accuracy', 'Precision', 'Recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caae905c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24760\\3400462355.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAISS</td>\n",
       "      <td>0.6988</td>\n",
       "      <td>0.671189</td>\n",
       "      <td>0.779445</td>\n",
       "      <td>0.721277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Method  Accuracy  Precision    Recall        F1\n",
       "0  FAISS    0.6988   0.671189  0.779445  0.721277"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions, average='binary')\n",
    "rec = recall_score(y_test, predictions, average='binary')\n",
    "f1 = f1_score(y_test, predictions, average='binary')\n",
    "\n",
    "new_row = pd.DataFrame([{\n",
    "    'Method': 'FAISS',\n",
    "    'Accuracy': acc,\n",
    "    'Precision': prec,\n",
    "    'Recall': rec,\n",
    "    'F1': f1\n",
    "}])\n",
    "\n",
    "metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)\n",
    "\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52e77a",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "# **BART Zero-shot**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba80c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "060e26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning,\n",
    "                        module=\"torch.utils.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8dbe8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAISS</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.671189</td>\n",
       "      <td>0.779445</td>\n",
       "      <td>0.721277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BART Zero-shot</td>\n",
       "      <td>0.810953</td>\n",
       "      <td>0.872417</td>\n",
       "      <td>0.728432</td>\n",
       "      <td>0.793949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Method  Accuracy  Precision    Recall        F1\n",
       "0           FAISS  0.698800   0.671189  0.779445  0.721277\n",
       "1  BART Zero-shot  0.810953   0.872417  0.728432  0.793949"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Review: the title helpfully offers the most succinct review of it you'll read anywhere ....\n",
      "Predicted: positive with confidence 0.8786\n",
      "--------------------------------------------------\n",
      "Review: even on those rare occasions when the narrator stops yammering , miller's hand often feels unsure ....\n",
      "Predicted: negative with confidence 0.9184\n",
      "--------------------------------------------------\n",
      "Review: a really funny fifteen-minute short stretched beyond its limits to fill an almost feature-length fil...\n",
      "Predicted: positive with confidence 0.9608\n",
      "--------------------------------------------------\n",
      "Review: equlibrium could pass for a thirteen-year-old's book report on the totalitarian themes of 1984 and f...\n",
      "Predicted: negative with confidence 0.9778\n",
      "--------------------------------------------------\n",
      "Review: the filmmakers try to balance pointed , often incisive satire and unabashed sweetness , with results...\n",
      "Predicted: positive with confidence 0.7912\n"
     ]
    }
   ],
   "source": [
    "zero_shot_classifier = pipeline(\"zero-shot-classification\",\n",
    "                                model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "all_results = zero_shot_classifier(\n",
    "    X_test.tolist(),\n",
    "    candidate_labels,\n",
    "    multi_label=False\n",
    ")\n",
    "\n",
    "preds = [1 if res['labels'][0] == 'positive' else 0 for res in all_results]\n",
    "\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "new_row = pd.DataFrame([{\n",
    "    'Method': 'BART Zero-shot',\n",
    "    'Accuracy': acc,\n",
    "    'Precision': prec,\n",
    "    'Recall': rec,\n",
    "    'F1': f1\n",
    "}])\n",
    "\n",
    "metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)\n",
    "\n",
    "display(metrics_df)\n",
    "\n",
    "for review, res in zip(X_test.iloc[:5], all_results[:5]):\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Review: {review[:100]}...\")\n",
    "    print(\n",
    "        f\"Predicted: {res['labels'][0]} with confidence {res['scores'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8937a8",
   "metadata": {},
   "source": [
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "# **TF-IDF + Logistic Regression**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c747fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 3,635\n",
      "Shape of X_train_vectorized: (7996, 3635)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=5)\n",
    "X_train_tfidf_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print('Number of features = {:,}'.format(\n",
    "    len(tfidf_vectorizer.get_feature_names_out())))\n",
    "print('Shape of X_train_vectorized:', X_train_tfidf_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b7dfc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      " ['cia' 'private' 'willis' 'ponder' 'specific' 'pulling' 'carefully'\n",
      " 'homes' 'cost' 'came']\n",
      "Largest tfidf:\n",
      " ['reality' 'silly' 'tasty' 'calculated' 'retro' 'satisfying' 'out'\n",
      " 'disappointment' 'shallow' 'cinematic']\n"
     ]
    }
   ],
   "source": [
    "sorted_tfidf_index = X_train_tfidf_vectorized.max(axis=0).toarray()[0].argsort()\n",
    "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print('Smallest tfidf:\\n', feature_names[sorted_tfidf_index[:10]])\n",
    "print('Largest tfidf:\\n', feature_names[sorted_tfidf_index[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c26ecf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_tfidf_vectorized, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test_tfidf_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10cd22cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAISS</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.671189</td>\n",
       "      <td>0.779445</td>\n",
       "      <td>0.721277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BART Zero-shot</td>\n",
       "      <td>0.810953</td>\n",
       "      <td>0.872417</td>\n",
       "      <td>0.728432</td>\n",
       "      <td>0.793949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF + Logistic Regression</td>\n",
       "      <td>0.764816</td>\n",
       "      <td>0.759178</td>\n",
       "      <td>0.775694</td>\n",
       "      <td>0.767347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Method  Accuracy  Precision    Recall        F1\n",
       "0                         FAISS  0.698800   0.671189  0.779445  0.721277\n",
       "1                BART Zero-shot  0.810953   0.872417  0.728432  0.793949\n",
       "2  TF-IDF + Logistic Regression  0.764816   0.759178  0.775694  0.767347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, predictions)\n",
    "prec = precision_score(y_test, predictions)\n",
    "rec = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "new_row = pd.DataFrame([{\n",
    "    'Method': 'TF-IDF + Logistic Regression',\n",
    "    'Accuracy': acc,\n",
    "    'Precision': prec,\n",
    "    'Recall': rec,\n",
    "    'F1': f1\n",
    "}])\n",
    "\n",
    "metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)\n",
    "\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366863a0",
   "metadata": {},
   "source": [
    "BART Zero-shot showed the best results in terms of accuracy and F1-score. This means that it is best at identifying whether a review is positive or negative. However, this method was the slowest because the model is large and processing texts takes a long time.\n",
    "\n",
    "TF-IDF with Logistic Regression showed slightly lower accuracy, but it works very quickly, making it convenient for processing large numbers of reviews.\n",
    "\n",
    "FAISS had the lowest accuracy, although it is also quite fast. It can be used if you need a quick search for similar texts rather than maximum classification accuracy.\n",
    "\n",
    "Overall, if accuracy is a priority, BART is the best choice. If speed is important, TF-IDF with Logistic Regression is the best option.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
